{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "no_words = 34016\n",
    "no_epochs = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '.'\n",
    "\n",
    "x_train = np.load(os.path.join(dir_path, '..', 'npy', 'x_train_rnn.npy'), allow_pickle=True)\n",
    "x_test = np.load(os.path.join(dir_path, '..', 'npy', 'x_test_rnn.npy'), allow_pickle=True)\n",
    "y_train = np.load(os.path.join(dir_path, '..', 'npy', 'y_train_rnn.npy'), allow_pickle=True)\n",
    "y_test = np.load(os.path.join(dir_path, '..', 'npy', 'y_test_rnn.npy'), allow_pickle=True)\n",
    "\n",
    "MAX_DOCUMENT_LENGTH = 100\n",
    "HIDDEN_SIZE = 20\n",
    "MAX_LABEL = 15\n",
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "lr = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 400],\n",
       "       [2, 400],\n",
       "       [3, 400],\n",
       "       [4, 400],\n",
       "       [5, 400],\n",
       "       [6, 400],\n",
       "       [7, 400],\n",
       "       [8, 400],\n",
       "       [9, 400],\n",
       "       [10, 400],\n",
       "       [11, 400],\n",
       "       [12, 400],\n",
       "       [13, 400],\n",
       "       [14, 400]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-ba50915add5e>:10: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "word_vectors:  [array([5600,  100,   50], dtype=int32)]\n",
      "word_list:  [array([ 100, 5600,   50], dtype=int32)]\n",
      "encoding:  [array([5600,   20], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "def rnn_model(x, withDropout):\n",
    "    \n",
    "    global no_words\n",
    "\n",
    "    word_vectors = tf.contrib.layers.embed_sequence(\n",
    "        x, vocab_size=no_words, embed_dim=EMBEDDING_SIZE)\n",
    "\n",
    "    word_list = tf.unstack(word_vectors, axis=1)\n",
    "\n",
    "    cell = tf.nn.rnn_cell.BasicRNNCell(HIDDEN_SIZE)\n",
    "    _, encoding = tf.nn.static_rnn(cell, word_list, dtype=tf.float32)\n",
    "\n",
    "#     logits = tf.layers.dense(encoding, MAX_LABEL, activation=None)\n",
    "#     if withDropout:\n",
    "#             logits = tf.layers.dropout(logits)\n",
    "\n",
    "    return word_vectors, word_list, encoding\n",
    "\n",
    "\n",
    "def train(withDropout):\n",
    "\n",
    "    global x_train, x_test, y_train, y_test, no_epochs\n",
    "\n",
    "    # Create the model\n",
    "    x = tf.placeholder(tf.int64, [None, MAX_DOCUMENT_LENGTH])\n",
    "    y_ = tf.placeholder(tf.int64)\n",
    "\n",
    "    word_vectors, word_list, encoding = rnn_model(x, withDropout)\n",
    "\n",
    "#     Optimizer\n",
    "#     entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.one_hot(y_, MAX_LABEL), logits=logits))\n",
    "#     train_op = tf.train.AdamOptimizer(lr).minimize(entropy)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    print('word_vectors: ', sess.run([tf.shape(word_vectors)], {x: x_train, y_: y_train}))\n",
    "    print('word_list: ', sess.run([tf.shape(word_list)], {x: x_train, y_: y_train}))\n",
    "    print('encoding: ', sess.run([tf.shape(encoding)], {x: x_train, y_: y_train}))\n",
    "#     print('logits: ', sess.run([tf.shape(logits)], {x: x_train, y_: y_train}))\n",
    "\n",
    "\n",
    "#     entropy_on_training = []\n",
    "#     accuracy_on_testing = []\n",
    "\n",
    "#     timeRecoder = TimeRecoder()\n",
    "#     timeRecoder.start()\n",
    "\n",
    "#     for e in range(no_epochs):\n",
    "\n",
    "#         x_train, y_train = shuffle(x_train, y_train)\n",
    "        \n",
    "#         # training\n",
    "#         _, loss_  = sess.run([train_op, entropy], {x: x_train, y_: y_train})\n",
    "#         entropy_on_training.append(loss_)\n",
    "        \n",
    "#         # testing\n",
    "#         predict = sess.run([logits], {x: x_test})\n",
    "#         accuracy_on_testing.append(accuracy_score(list(y_test), list(np.argmax(np.array(predict[0]), axis=1))))\n",
    "        \n",
    "        \n",
    "#         print('epoch %d: entropy: %f, accuracy: %f' % (e, entropy_on_training[-1], accuracy_on_testing[-1]))\n",
    "        \n",
    "#     timeRecoder.end()\n",
    "\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# print('\\n\\n {} \\n With Dropout ... \\n {} \\n\\n'.format('-'*40, '-'*40,))\n",
    "train(withDropout=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
