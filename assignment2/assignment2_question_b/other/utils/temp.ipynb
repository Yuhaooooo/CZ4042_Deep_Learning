{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "no_words = 34016\n",
    "no_epochs = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '.'\n",
    "\n",
    "x_train_c = np.load(os.path.join(dir_path, '..', 'npy', 'x_train_char.npy'), allow_pickle=True)\n",
    "x_test_c = np.load(os.path.join(dir_path, '..', 'npy', 'x_test_char.npy'), allow_pickle=True)\n",
    "y_train_c = np.load(os.path.join(dir_path, '..', 'npy', 'y_train_char.npy'), allow_pickle=True)\n",
    "y_test_c = np.load(os.path.join(dir_path, '..', 'npy', 'y_test_char.npy'), allow_pickle=True)\n",
    "\n",
    "x_train_w = np.load(os.path.join(dir_path, '..', 'npy', 'x_train_word.npy'), allow_pickle=True)\n",
    "x_test_w = np.load(os.path.join(dir_path, '..', 'npy', 'x_test_word.npy'), allow_pickle=True)\n",
    "y_train_w = np.load(os.path.join(dir_path, '..', 'npy', 'y_train_word.npy'), allow_pickle=True)\n",
    "y_test_w = np.load(os.path.join(dir_path, '..', 'npy', 'y_test_word.npy'), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2272, 9045,  130, 3612, 9986, 9987,  699, 9988, 9989,  130,  131,\n",
       "       1177,  134, 1733, 1135, 2271, 9990, 9991, 2272, 9992,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_w[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_w[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_vectors:  [array([100,  20], dtype=int32)]\n",
      "word_list:  [array([ 100, 5600,   20], dtype=int32)]\n",
      "encoding:  [array([5600,   20], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "no_words = 34016\n",
    "no_epochs = 3000\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "\n",
    "MAX_DOCUMENT_LENGTH = 100\n",
    "EMBEDDING_SIZE = 20\n",
    "MAX_LABEL = 15\n",
    "HIDDEN_SIZE = 20\n",
    "\n",
    "\n",
    "def rnn_model(x, withDropout):\n",
    "    \n",
    "    global no_words\n",
    "\n",
    "    word_vectors = tf.contrib.layers.embed_sequence(\n",
    "        x, vocab_size=no_words, embed_dim=EMBEDDING_SIZE)\n",
    "\n",
    "    word_list = tf.unstack(word_vectors, axis=1)\n",
    "\n",
    "    cell = tf.nn.rnn_cell.BasicRNNCell(HIDDEN_SIZE)\n",
    "    _, encoding = tf.nn.static_rnn(cell, word_list, dtype=tf.float32)\n",
    "\n",
    "#     logits = tf.layers.dense(encoding, MAX_LABEL, activation=None)\n",
    "#     if withDropout:\n",
    "#             logits = tf.layers.dropout(logits)\n",
    "\n",
    "    return word_vectors, word_list, encoding\n",
    "\n",
    "\n",
    "def train(withDropout):\n",
    "\n",
    "    global x_train, x_test, y_train, y_test, no_epochs\n",
    "\n",
    "    # Create the model\n",
    "    x = tf.placeholder(tf.int64, [None, MAX_DOCUMENT_LENGTH])\n",
    "    y_ = tf.placeholder(tf.int64)\n",
    "\n",
    "    word_vectors, word_list, encoding = rnn_model(x, withDropout)\n",
    "\n",
    "#     Optimizer\n",
    "#     entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.one_hot(y_, MAX_LABEL), logits=logits))\n",
    "#     train_op = tf.train.AdamOptimizer(lr).minimize(entropy)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    print('word_vectors: ', sess.run([tf.shape(word_vectors[1000])], {x: x_train_w, y_: y_train_w}))\n",
    "    print('word_list: ', sess.run([tf.shape(word_list)], {x: x_train_w, y_: y_train_w}))\n",
    "    print('encoding: ', sess.run([tf.shape(encoding)], {x: x_train_w, y_: y_train_w}))\n",
    "#     print('logits: ', sess.run([tf.shape(logits)], {x: x_train, y_: y_train}))\n",
    "\n",
    "\n",
    "#     entropy_on_training = []\n",
    "#     accuracy_on_testing = []\n",
    "\n",
    "#     timeRecoder = TimeRecoder()\n",
    "#     timeRecoder.start()\n",
    "\n",
    "#     for e in range(no_epochs):\n",
    "\n",
    "#         x_train, y_train = shuffle(x_train, y_train)\n",
    "        \n",
    "#         # training\n",
    "#         _, loss_  = sess.run([train_op, entropy], {x: x_train, y_: y_train})\n",
    "#         entropy_on_training.append(loss_)\n",
    "        \n",
    "#         # testing\n",
    "#         predict = sess.run([logits], {x: x_test})\n",
    "#         accuracy_on_testing.append(accuracy_score(list(y_test), list(np.argmax(np.array(predict[0]), axis=1))))\n",
    "        \n",
    "        \n",
    "#         print('epoch %d: entropy: %f, accuracy: %f' % (e, entropy_on_training[-1], accuracy_on_testing[-1]))\n",
    "        \n",
    "#     timeRecoder.end()\n",
    "\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# print('\\n\\n {} \\n With Dropout ... \\n {} \\n\\n'.format('-'*40, '-'*40,))\n",
    "train(withDropout=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2272, 9045,  130, 3612, 9986, 9987,  699, 9988, 9989,  130,  131,\n",
       "       1177,  134, 1733, 1135, 2271, 9990, 9991, 2272, 9992,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
