{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "no_words = 34016\n",
    "no_epochs = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '.'\n",
    "\n",
    "x_train_c = np.load(os.path.join(dir_path, '..', 'npy', 'x_train_char.npy'), allow_pickle=True)\n",
    "x_test_c = np.load(os.path.join(dir_path, '..', 'npy', 'x_test_char.npy'), allow_pickle=True)\n",
    "y_train_c = np.load(os.path.join(dir_path, '..', 'npy', 'y_train_char.npy'), allow_pickle=True)\n",
    "y_test_c = np.load(os.path.join(dir_path, '..', 'npy', 'y_test_char.npy'), allow_pickle=True)\n",
    "\n",
    "x_train_w = np.load(os.path.join(dir_path, '..', 'npy', 'x_train_word.npy'), allow_pickle=True)\n",
    "x_test_w = np.load(os.path.join(dir_path, '..', 'npy', 'x_test_word.npy'), allow_pickle=True)\n",
    "y_train_w = np.load(os.path.join(dir_path, '..', 'npy', 'y_train_word.npy'), allow_pickle=True)\n",
    "y_test_w = np.load(os.path.join(dir_path, '..', 'npy', 'y_test_word.npy'), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2272, 9045,  130, 3612, 9986, 9987,  699, 9988, 9989,  130,  131,\n",
       "       1177,  134, 1733, 1135, 2271, 9990, 9991, 2272, 9992,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_w[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_w[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_vectors:  [array([100,  20], dtype=int32)]\n",
      "word_list:  [array([ 100, 5600,   20], dtype=int32)]\n",
      "encoding:  [array([5600,   20], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "no_words = 34016\n",
    "no_epochs = 3000\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "\n",
    "MAX_DOCUMENT_LENGTH = 100\n",
    "EMBEDDING_SIZE = 20\n",
    "MAX_LABEL = 15\n",
    "HIDDEN_SIZE = 20\n",
    "\n",
    "\n",
    "def rnn_model(x, withDropout):\n",
    "    \n",
    "    global no_words\n",
    "\n",
    "    word_vectors = tf.contrib.layers.embed_sequence(\n",
    "        x, vocab_size=no_words, embed_dim=EMBEDDING_SIZE)\n",
    "\n",
    "    word_list = tf.unstack(word_vectors, axis=1)\n",
    "\n",
    "    cell = tf.nn.rnn_cell.BasicRNNCell(HIDDEN_SIZE)\n",
    "    _, encoding = tf.nn.static_rnn(cell, word_list, dtype=tf.float32)\n",
    "\n",
    "#     logits = tf.layers.dense(encoding, MAX_LABEL, activation=None)\n",
    "#     if withDropout:\n",
    "#             logits = tf.layers.dropout(logits)\n",
    "\n",
    "    return word_vectors, word_list, encoding\n",
    "\n",
    "\n",
    "def train(withDropout):\n",
    "\n",
    "    global x_train, x_test, y_train, y_test, no_epochs\n",
    "\n",
    "    # Create the model\n",
    "    x = tf.placeholder(tf.int64, [None, MAX_DOCUMENT_LENGTH])\n",
    "    y_ = tf.placeholder(tf.int64)\n",
    "\n",
    "    word_vectors, word_list, encoding = rnn_model(x, withDropout)\n",
    "\n",
    "#     Optimizer\n",
    "#     entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.one_hot(y_, MAX_LABEL), logits=logits))\n",
    "#     train_op = tf.train.AdamOptimizer(lr).minimize(entropy)\n",
    "train_op = tf.train.GradientDescentOptimizer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    print('word_vectors: ', sess.run([tf.shape(word_vectors[1000])], {x: x_train_w, y_: y_train_w}))\n",
    "    print('word_list: ', sess.run([tf.shape(word_list)], {x: x_train_w, y_: y_train_w}))\n",
    "    print('encoding: ', sess.run([tf.shape(encoding)], {x: x_train_w, y_: y_train_w}))\n",
    "#     print('logits: ', sess.run([tf.shape(logits)], {x: x_train, y_: y_train}))\n",
    "\n",
    "\n",
    "#     entropy_on_training = []\n",
    "#     accuracy_on_testing = []\n",
    "\n",
    "#     timeRecoder = TimeRecoder()\n",
    "#     timeRecoder.start()\n",
    "\n",
    "#     for e in range(no_epochs):\n",
    "\n",
    "#         x_train, y_train = shuffle(x_train, y_train)\n",
    "        \n",
    "#         # training\n",
    "#         _, loss_  = sess.run([train_op, entropy], {x: x_train, y_: y_train})\n",
    "#         entropy_on_training.append(loss_)\n",
    "        \n",
    "#         # testing\n",
    "#         predict = sess.run([logits], {x: x_test})\n",
    "#         accuracy_on_testing.append(accuracy_score(list(y_test), list(np.argmax(np.array(predict[0]), axis=1))))\n",
    "        \n",
    "        \n",
    "#         print('epoch %d: entropy: %f, accuracy: %f' % (e, entropy_on_training[-1], accuracy_on_testing[-1]))\n",
    "        \n",
    "#     timeRecoder.end()\n",
    "\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# print('\\n\\n {} \\n With Dropout ... \\n {} \\n\\n'.format('-'*40, '-'*40,))\n",
    "train(withDropout=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2272, 9045,  130, 3612, 9986, 9987,  699, 9988, 9989,  130,  131,\n",
       "       1177,  134, 1733, 1135, 2271, 9990, 9991, 2272, 9992,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5600/5600 [==============================] - 3s 492us/step - loss: 2.7025 - accuracy: 0.0700\n",
      "Epoch 2/20\n",
      "5600/5600 [==============================] - 2s 430us/step - loss: 2.6920 - accuracy: 0.0702\n",
      "Epoch 3/20\n",
      "5600/5600 [==============================] - 2s 397us/step - loss: 2.6781 - accuracy: 0.0748\n",
      "Epoch 4/20\n",
      "5600/5600 [==============================] - 2s 403us/step - loss: 2.6711 - accuracy: 0.0689\n",
      "Epoch 5/20\n",
      "5600/5600 [==============================] - 2s 410us/step - loss: 2.6676 - accuracy: 0.0750\n",
      "Epoch 6/20\n",
      "5600/5600 [==============================] - 2s 387us/step - loss: 2.6651 - accuracy: 0.0670\n",
      "Epoch 7/20\n",
      "5600/5600 [==============================] - 2s 399us/step - loss: 2.6617 - accuracy: 0.0727\n",
      "Epoch 8/20\n",
      "5600/5600 [==============================] - 2s 401us/step - loss: 2.6600 - accuracy: 0.0704\n",
      "Epoch 9/20\n",
      "5600/5600 [==============================] - 2s 416us/step - loss: 2.6605 - accuracy: 0.0702\n",
      "Epoch 10/20\n",
      "5600/5600 [==============================] - 3s 478us/step - loss: 2.6552 - accuracy: 0.0736\n",
      "Epoch 11/20\n",
      "5600/5600 [==============================] - 3s 457us/step - loss: 2.6559 - accuracy: 0.0712\n",
      "Epoch 12/20\n",
      "5600/5600 [==============================] - 2s 443us/step - loss: 2.6512 - accuracy: 0.0718\n",
      "Epoch 13/20\n",
      "5600/5600 [==============================] - 2s 444us/step - loss: 2.6539 - accuracy: 0.0720\n",
      "Epoch 14/20\n",
      "5600/5600 [==============================] - 3s 447us/step - loss: 2.6541 - accuracy: 0.0684\n",
      "Epoch 15/20\n",
      "5600/5600 [==============================] - 3s 450us/step - loss: 2.6517 - accuracy: 0.0718\n",
      "Epoch 16/20\n",
      "5600/5600 [==============================] - 3s 456us/step - loss: 2.6515 - accuracy: 0.0696\n",
      "Epoch 17/20\n",
      "5600/5600 [==============================] - 2s 442us/step - loss: 2.6511 - accuracy: 0.0716\n",
      "Epoch 18/20\n",
      "5600/5600 [==============================] - 3s 450us/step - loss: 2.6510 - accuracy: 0.0695\n",
      "Epoch 19/20\n",
      "5600/5600 [==============================] - 2s 436us/step - loss: 2.6480 - accuracy: 0.0702\n",
      "Epoch 20/20\n",
      "5600/5600 [==============================] - 2s 435us/step - loss: 2.6468 - accuracy: 0.0727\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim = no_words, output_dim = 20, input_length = MAX_DOCUMENT_LENGTH))\n",
    "model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(20, dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(20, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(15, activation = 'softmax'))\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model_lstm.fit(\n",
    "    x_train_w,\n",
    "    to_categorical(y_train_w),\n",
    "    epochs = 20,\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(dir_path, 'other', 'npy', 'word_2rnn_entropy_on_training_withDropout.npy'), np.array(entropy_on_training))\n",
    "        np.save(os.path.join(dir_path, 'other', 'npy', 'word_2rnn_accuracy_on_testing_withDropout.npy'), np.array(accuracy_on_testing))\n",
    "\n",
    "        #plot\n",
    "        plt.figure()\n",
    "        plt.plot(entropy_on_training)\n",
    "        plt.plot(accuracy_on_testing)\n",
    "        plt.title('entropy / accuracy word cnn with dropout')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['entropy_on_training', 'accuracy_on_testing',], loc='upper left')\n",
    "        plt.savefig(os.path.join(dir_path, 'other', 'figure', 'word_2rnn_withDropout.png'))  \n",
    "\n",
    "    else:\n",
    "        np.save(os.path.join(dir_path, 'other', 'npy', 'word_2rnn_entropy_on_training_withoutDropout.npy'), np.array(entropy_on_training))\n",
    "        np.save(os.path.join(dir_path, 'other', 'npy', 'word_2rnn_accuracy_on_testing_withoutDropout.npy'), np.array(accuracy_on_testing))\n",
    "\n",
    "        #plot\n",
    "        plt.figure()\n",
    "        plt.plot(entropy_on_training)\n",
    "        plt.plot(accuracy_on_testing)\n",
    "        plt.title('entropy / accuracy word cnn without dropout')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['entropy_on_training', 'accuracy_on_testing',], loc='upper left')\n",
    "        plt.savefig(os.path.join(dir_path, 'other', 'figure', 'word_2rnn_withoutDropout.png'))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
