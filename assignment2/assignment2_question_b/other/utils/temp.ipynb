{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "no_words = 34016\n",
    "no_epochs = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '.'\n",
    "\n",
    "x_train_c = np.load(os.path.join(dir_path, '..', 'npy', 'x_train_char.npy'), allow_pickle=True)\n",
    "x_test_c = np.load(os.path.join(dir_path, '..', 'npy', 'x_test_char.npy'), allow_pickle=True)\n",
    "y_train_c = np.load(os.path.join(dir_path, '..', 'npy', 'y_train_char.npy'), allow_pickle=True)\n",
    "y_test_c = np.load(os.path.join(dir_path, '..', 'npy', 'y_test_char.npy'), allow_pickle=True)\n",
    "\n",
    "x_train_w = np.load(os.path.join(dir_path, '..', 'npy', 'x_train_word.npy'), allow_pickle=True)\n",
    "x_test_w = np.load(os.path.join(dir_path, '..', 'npy', 'x_test_word.npy'), allow_pickle=True)\n",
    "y_train_w = np.load(os.path.join(dir_path, '..', 'npy', 'y_train_word.npy'), allow_pickle=True)\n",
    "y_test_w = np.load(os.path.join(dir_path, '..', 'npy', 'y_test_word.npy'), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2272, 9045,  130, 3612, 9986, 9987,  699, 9988, 9989,  130,  131,\n",
       "       1177,  134, 1733, 1135, 2271, 9990, 9991, 2272, 9992,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_w[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_w[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-96-faeb9db4ec52>:21: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/heyuhao/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "word_vectors:  [array([5600,  100,   20], dtype=int32)]\n",
      "word_list:  [array([ 100, 5600,   20], dtype=int32)]\n",
      "encoding:  [array([5600,   20], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "no_words = 34016\n",
    "no_epochs = 3000\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "\n",
    "MAX_DOCUMENT_LENGTH = 100\n",
    "EMBEDDING_SIZE = 20\n",
    "MAX_LABEL = 15\n",
    "HIDDEN_SIZE = 20\n",
    "\n",
    "\n",
    "def rnn_model(x, withDropout):\n",
    "    \n",
    "    global no_words\n",
    "\n",
    "    word_vectors = tf.contrib.layers.embed_sequence(\n",
    "        x, vocab_size=no_words, embed_dim=EMBEDDING_SIZE)\n",
    "\n",
    "    word_list = tf.unstack(word_vectors, axis=1)\n",
    "\n",
    "    cell = tf.nn.rnn_cell.GRUCell(HIDDEN_SIZE)\n",
    "    _, encoding = tf.nn.static_rnn(cell, word_list, dtype=tf.float32)\n",
    "\n",
    "#     logits = tf.layers.dense(encoding, MAX_LABEL, activation=None)\n",
    "#     if withDropout:\n",
    "#             logits = tf.layers.dropout(logits)\n",
    "\n",
    "    return word_vectors, word_list, encoding\n",
    "\n",
    "\n",
    "def train(withDropout):\n",
    "\n",
    "    global x_train, x_test, y_train, y_test, no_epochs\n",
    "\n",
    "    # Create the model\n",
    "    x = tf.placeholder(tf.int64, [None, MAX_DOCUMENT_LENGTH])\n",
    "    y_ = tf.placeholder(tf.int64)\n",
    "\n",
    "    word_vectors, word_list, encoding = rnn_model(x, withDropout)\n",
    "\n",
    "#     Optimizer\n",
    "#     entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.one_hot(y_, MAX_LABEL), logits=logits))\n",
    "#     train_op = tf.train.AdamOptimizer(lr).minimize(entropy)\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    print('word_vectors: ', sess.run([tf.shape(word_vectors)], {x: x_train_w, y_: y_train_w}))\n",
    "    print('word_list: ', sess.run([tf.shape(word_list)], {x: x_train_w, y_: y_train_w}))\n",
    "    print('encoding: ', sess.run([tf.shape(encoding)], {x: x_train_w, y_: y_train_w}))\n",
    "#     print('logits: ', sess.run([tf.shape(logits)], {x: x_train, y_: y_train}))\n",
    "\n",
    "\n",
    "#     entropy_on_training = []\n",
    "#     accuracy_on_testing = []\n",
    "\n",
    "#     timeRecoder = TimeRecoder()\n",
    "#     timeRecoder.start()\n",
    "\n",
    "#     for e in range(no_epochs):\n",
    "\n",
    "#         x_train, y_train = shuffle(x_train, y_train)\n",
    "        \n",
    "#         # training\n",
    "#         _, loss_  = sess.run([train_op, entropy], {x: x_train, y_: y_train})\n",
    "#         entropy_on_training.append(loss_)\n",
    "        \n",
    "#         # testing\n",
    "#         predict = sess.run([logits], {x: x_test})\n",
    "#         accuracy_on_testing.append(accuracy_score(list(y_test), list(np.argmax(np.array(predict[0]), axis=1))))\n",
    "        \n",
    "        \n",
    "#         print('epoch %d: entropy: %f, accuracy: %f' % (e, entropy_on_training[-1], accuracy_on_testing[-1]))\n",
    "        \n",
    "#     timeRecoder.end()\n",
    "\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# print('\\n\\n {} \\n With Dropout ... \\n {} \\n\\n'.format('-'*40, '-'*40,))\n",
    "train(withDropout=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2272, 9045,  130, 3612, 9986, 9987,  699, 9988, 9989,  130,  131,\n",
       "       1177,  134, 1733, 1135, 2271, 9990, 9991, 2272, 9992,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_2: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-2c978f3db59e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpatialDropout1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_2: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim = no_words, output_dim = 20, input_length = MAX_DOCUMENT_LENGTH))\n",
    "model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(20, dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(LSTM(20, dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(20, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(15, activation = 'softmax'))\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model_lstm.fit(\n",
    "    x_train_w,\n",
    "    to_categorical(y_train_w),\n",
    "    epochs = 20,\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(dir_path, 'other', 'npy', 'char_gru_clipping_entropy_on_training_withDropout.npy'), np.array(entropy_on_training))\n",
    "        np.save(os.path.join(dir_path, 'other', 'npy', 'char_gru_clipping_accuracy_on_testing_withDropout.npy'), np.array(accuracy_on_testing))\n",
    "\n",
    "        #plot\n",
    "        plt.figure()\n",
    "        plt.plot(entropy_on_training)\n",
    "        plt.plot(accuracy_on_testing)\n",
    "        plt.title('entropy / accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['entropy_on_training', 'accuracy_on_testing',], loc='upper left')\n",
    "        plt.savefig(os.path.join(dir_path, 'other', 'figure', 'char_gru_clipping_withDropout.png'))  \n",
    "\n",
    "    else:\n",
    "        np.save(os.path.join(dir_path, 'other', 'npy', 'char_gru_clipping_entropy_on_training_withoutDropout.npy'), np.array(entropy_on_training))\n",
    "        np.save(os.path.join(dir_path, 'other', 'npy', 'char_gru_clipping_accuracy_on_testing_withoutDropout.npy'), np.array(accuracy_on_testing))\n",
    "\n",
    "        #plot\n",
    "        plt.figure()\n",
    "        plt.plot(entropy_on_training)\n",
    "        plt.plot(accuracy_on_testing)\n",
    "        plt.title('entropy / accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['entropy_on_training', 'accuracy_on_testing',], loc='upper left')\n",
    "        plt.savefig(os.path.join(dir_path, 'other', 'figure', 'char_gru_clipping_withoutDropout.png')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
